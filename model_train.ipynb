{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92cc8f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4220ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/cleaned_train.csv')\n",
    "test = pd.read_csv('./data/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22583eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = ['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
    "       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n",
    "       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n",
    "       'Outlet_Type', 'Item_Outlet_Sales', 'Outlet_Age', ]\n",
    "    #    'MRP_bin','Vis_per_Weight', 'Is_New_Outlet']       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5722c2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250816_152405\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.11.7\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.6.0: Mon Jul 14 11:30:40 PDT 2025; root:xnu-11417.140.69~1/RELEASE_ARM64_T6041\n",
      "CPU Count:          12\n",
      "Memory Avail:       8.63 GB / 24.00 GB (35.9%)\n",
      "Disk Space Avail:   284.07 GB / 460.43 GB (61.7%)\n",
      "===================================================\n",
      "Presets specified: ['high_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-08-16 20:54:06,756\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/Users/simran/Developer/hackathon/AutogluonModels/ag-20250816_152405/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Beginning AutoGluon training ... Time limit = 149s\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m AutoGluon will save models to \"/Users/simran/Developer/hackathon/AutogluonModels/ag-20250816_152405/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Train Data Rows:    7576\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Train Data Columns: 12\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Label Column:       Item_Outlet_Sales\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tAvailable Memory:                    8937.19 MB\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tTrain Data (Original)  Memory Usage: 3.58 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\t('float', [])  : 3 | ['Item_Weight', 'Item_Visibility', 'Item_MRP']\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\t('int', [])    : 2 | ['Outlet_Establishment_Year', 'Outlet_Age']\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\t('object', []) : 7 | ['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size', ...]\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\t('category', []) : 7 | ['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size', ...]\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\t('float', [])    : 3 | ['Item_Weight', 'Item_Visibility', 'Item_MRP']\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\t('int', [])      : 2 | ['Outlet_Establishment_Year', 'Outlet_Age']\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t12 features in original data used to generate 12 features in processed data.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.35 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t'RF': [{}],\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t'GBM': [{}],\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t'XGB': [{}],\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t'CAT': [{}],\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t'KNN': [{}],\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t'LR': [{}],\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t'XT': [{}],\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting 7 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: KNeighbors_BAG_L1 ... Training model for up to 98.97s of the 148.50s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-1526.9747\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 98.26s of the 147.78s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-1097.5316\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: RandomForest_BAG_L1 ... Training model for up to 96.90s of the 146.43s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-1142.1276\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.96s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 95.70s of the 145.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.42%)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-1080.9347\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t4.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: ExtraTrees_BAG_L1 ... Training model for up to 90.44s of the 139.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-1122.7114\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.33s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 89.87s of the 139.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-1094.063\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: LinearModel_BAG_L1 ... Training model for up to 87.97s of the 137.50s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-1229.4604\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 148.50s of the 136.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.929, 'ExtraTrees_BAG_L1': 0.071}\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-1080.6699\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting 6 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 136.20s of the 136.20s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-1083.6127\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.42s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: RandomForest_BAG_L2 ... Training model for up to 134.63s of the 134.63s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-1078.0303\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t1.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 132.61s of the 132.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.65%)\n",
      "\u001b[36m(_ray_fit pid=53592)\u001b[0m \tRan out of time, early stopping on iteration 9698.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-936.4179\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t106.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.18s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: ExtraTrees_BAG_L2 ... Training model for up to 24.88s of the 24.87s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-1075.0452\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.66s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 23.96s of the 23.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-1084.8802\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t1.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: LinearModel_BAG_L2 ... Training model for up to 21.28s of the 21.28s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-899.9387\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.13s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 148.50s of the 20.10s of remaining time.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tEnsemble Weights: {'LinearModel_BAG_L2': 0.643, 'CatBoost_BAG_L2': 0.357}\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t-883.5535\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m AutoGluon training complete, total runtime = 128.45s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 2724.0 rows/s (947 batch size)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: KNeighbors_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_ray_fit pid=53594)\u001b[0m \tRan out of time, early stopping on iteration 9889.\u001b[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: RandomForest_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.96s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.26s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: ExtraTrees_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.33s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: LinearModel_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tWarning: Exception caused LinearModel_BAG_L1_FULL to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\tcannot set WRITEABLE flag to True of this array\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 365, in _fit\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     self._fit_single(\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 629, in _fit_single\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     model_base.fit(X=X_fit, y=y_fit, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/tabular/models/lr/lr_model.py\", line 238, in _fit\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     model = model.fit(**fit_args)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py\", line 1167, in fit\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     X, y = self._validate_data(\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/base.py\", line 650, in _validate_data\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     X, y = check_X_y(X, y, **check_params)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1279, in check_X_y\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1289, in _check_y\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     y = check_array(\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m         ^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1097, in check_array\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     array.flags.writeable = True\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m ValueError: cannot set WRITEABLE flag to True of this array\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m WARNING: Refit training failure detected for 'LinearModel_BAG_L1'... Falling back to using first fold to avoid downstream exception.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tThis is likely due to an out-of-memory error or other memory related issue. \n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tPlease create a GitHub issue if this was triggered from a non-memory related problem.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: LinearModel_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.929, 'ExtraTrees_BAG_L1': 0.071}\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: RandomForest_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t1.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t28.34s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: ExtraTrees_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.66s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: LinearModel_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tWarning: Exception caused LinearModel_BAG_L2_FULL to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t\tcannot set WRITEABLE flag to True of this array\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 365, in _fit\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     self._fit_single(\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 629, in _fit_single\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     model_base.fit(X=X_fit, y=y_fit, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/tabular/models/lr/lr_model.py\", line 238, in _fit\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     model = model.fit(**fit_args)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py\", line 1167, in fit\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     X, y = self._validate_data(\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/base.py\", line 650, in _validate_data\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     X, y = check_X_y(X, y, **check_params)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1279, in check_X_y\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1289, in _check_y\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     y = check_array(\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m         ^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m   File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1097, in check_array\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     array.flags.writeable = True\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m     ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m ValueError: cannot set WRITEABLE flag to True of this array\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m WARNING: Refit training failure detected for 'LinearModel_BAG_L2'... Falling back to using first fold to avoid downstream exception.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tThis is likely due to an out-of-memory error or other memory related issue. \n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tPlease create a GitHub issue if this was triggered from a non-memory related problem.\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: LinearModel_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \tEnsemble Weights: {'LinearModel_BAG_L2': 0.643, 'CatBoost_BAG_L2': 0.357}\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Refit complete, total runtime = 30.46s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/simran/Developer/hackathon/AutogluonModels/ag-20250816_152405/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=53484)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                       model  score_holdout    score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0        XGBoost_BAG_L1_FULL   -1015.238990 -1094.063026  root_mean_squared_error        0.017343            NaN   0.053564                 0.017343                     NaN           0.053564            1       True          6\n",
      "1   WeightedEnsemble_L2_FULL   -1015.739246 -1080.669874  root_mean_squared_error        0.111569            NaN   0.595794                 0.000514                     NaN           0.007963            2       True          8\n",
      "2       CatBoost_BAG_L1_FULL   -1017.121805 -1080.934693  root_mean_squared_error        0.005524            NaN   0.260981                 0.005524                     NaN           0.260981            1       True          4\n",
      "3       LightGBM_BAG_L1_FULL   -1024.857476 -1097.531617  root_mean_squared_error        0.002573            NaN   0.237808                 0.002573                     NaN           0.237808            1       True          2\n",
      "4   RandomForest_BAG_L2_FULL   -1026.773389 -1078.030313  root_mean_squared_error        0.359523            NaN   3.649436                 0.108787                0.171970           1.763561            2       True         10\n",
      "5       LightGBM_BAG_L2_FULL   -1027.597327 -1083.612655  root_mean_squared_error        0.254411            NaN   2.111357                 0.003675                     NaN           0.225482            2       True          9\n",
      "6     ExtraTrees_BAG_L2_FULL   -1028.999793 -1075.045223  root_mean_squared_error        0.339545            NaN   2.550095                 0.088810                0.166015           0.664220            2       True         12\n",
      "7     ExtraTrees_BAG_L1_FULL   -1044.330636 -1122.711442  root_mean_squared_error        0.105531       0.156528   0.326850                 0.105531                0.156528           0.326850            1       True          5\n",
      "8        XGBoost_BAG_L2_FULL   -1052.197032 -1084.880200  root_mean_squared_error        0.256881            NaN   2.000846                 0.006146                     NaN           0.114971            2       True         13\n",
      "9   RandomForest_BAG_L1_FULL   -1068.586108 -1142.127601  root_mean_squared_error        0.101393       0.166853   0.962994                 0.101393                0.166853           0.962994            1       True          3\n",
      "10  WeightedEnsemble_L3_FULL   -1069.028378  -883.553501  root_mean_squared_error        0.278071            NaN  30.294702                 0.000567                     NaN           0.011465            3       True         15\n",
      "11   LinearModel_BAG_L2_FULL   -1087.019627  -899.938715  root_mean_squared_error        0.255506            NaN   1.940216                 0.004770                0.003807           0.054341            2       True         14\n",
      "12      CatBoost_BAG_L2_FULL   -1111.626597  -936.417920  root_mean_squared_error        0.272734            NaN  30.228895                 0.021999                     NaN          28.343021            2       True         11\n",
      "13   LinearModel_BAG_L1_FULL   -1193.456931 -1229.460397  root_mean_squared_error        0.004195       0.002784   0.040967                 0.004195                0.002784           0.040967            1       True          7\n",
      "14    KNeighbors_BAG_L1_FULL   -1457.103186 -1526.974661  root_mean_squared_error        0.014176       0.028237   0.002711                 0.014176                0.028237           0.002711            1       True          1\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t162s\t = DyStack   runtime |\t438s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 438s\n",
      "AutoGluon will save models to \"/Users/simran/Developer/hackathon/AutogluonModels/ag-20250816_152405\"\n",
      "Train Data Rows:    8523\n",
      "Train Data Columns: 12\n",
      "Label Column:       Item_Outlet_Sales\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8341.50 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 3 | ['Item_Weight', 'Item_Visibility', 'Item_MRP']\n",
      "\t\t('int', [])    : 2 | ['Outlet_Establishment_Year', 'Outlet_Age']\n",
      "\t\t('object', []) : 7 | ['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 7 | ['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size', ...]\n",
      "\t\t('float', [])    : 3 | ['Item_Weight', 'Item_Visibility', 'Item_MRP']\n",
      "\t\t('int', [])      : 2 | ['Outlet_Establishment_Year', 'Outlet_Age']\n",
      "\t0.0s = Fit runtime\n",
      "\t12 features in original data used to generate 12 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.39 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "\t'GBM': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'CAT': [{}],\n",
      "\t'KNN': [{}],\n",
      "\t'LR': [{}],\n",
      "\t'XT': [{}],\n",
      "}\n",
      "Fitting 7 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighbors_BAG_L1 ... Training model for up to 437.91s of the 437.90s of remaining time.\n",
      "\t-1519.7364\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 437.06s of the 437.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t-1082.8938\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L1 ... Training model for up to 435.35s of the 435.35s of remaining time.\n",
      "\t-1134.4324\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 433.96s of the 433.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.34%)\n",
      "\t-1072.6848\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.13s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_BAG_L1 ... Training model for up to 427.00s of the 427.00s of remaining time.\n",
      "\t-1115.1388\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 426.39s of the 426.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t-1079.9937\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LinearModel_BAG_L1 ... Training model for up to 424.70s of the 424.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-1216.2758\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 423.45s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.783, 'LightGBM_BAG_L1': 0.087, 'XGBoost_BAG_L1': 0.087, 'ExtraTrees_BAG_L1': 0.043}\n",
      "\t-1072.117\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.53s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 10570.7 rows/s (1066 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighbors_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.29s\t = Training   runtime\n",
      "Fitting model: RandomForest_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.64s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.09s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LinearModel_BAG_L1_FULL ...\n",
      "\tWarning: Exception caused LinearModel_BAG_L1_FULL to fail during training... Skipping this model.\n",
      "\t\tcannot set WRITEABLE flag to True of this array\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 365, in _fit\n",
      "    self._fit_single(\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 629, in _fit_single\n",
      "    model_base.fit(X=X_fit, y=y_fit, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/autogluon/tabular/models/lr/lr_model.py\", line 238, in _fit\n",
      "    model = model.fit(**fit_args)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py\", line 1167, in fit\n",
      "    X, y = self._validate_data(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/base.py\", line 650, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1279, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1289, in _check_y\n",
      "    y = check_array(\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"/Users/simran/.pyenv/versions/common-env/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 1097, in check_array\n",
      "    array.flags.writeable = True\n",
      "    ^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: cannot set WRITEABLE flag to True of this array\n",
      "WARNING: Refit training failure detected for 'LinearModel_BAG_L1'... Falling back to using first fold to avoid downstream exception.\n",
      "\tThis is likely due to an out-of-memory error or other memory related issue. \n",
      "\tPlease create a GitHub issue if this was triggered from a non-memory related problem.\n",
      "Fitting model: LinearModel_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.783, 'LightGBM_BAG_L1': 0.087, 'XGBoost_BAG_L1': 0.087, 'ExtraTrees_BAG_L1': 0.043}\n",
      "\t0.01s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 1.45s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/simran/Developer/hackathon/AutogluonModels/ag-20250816_152405\")\n"
     ]
    }
   ],
   "source": [
    "train = train[final_columns].copy()\n",
    "test = test[final_columns].copy()\n",
    "\n",
    "# Preserve original IDs for submission\n",
    "test_original_ids = test[['Item_Identifier', 'Outlet_Identifier']].copy()\n",
    "\n",
    "cat_params = {\n",
    "    'loss_function': 'RMSE',\n",
    "    'depth': 8,               \n",
    "    'l2_leaf_reg': 2.0,      \n",
    "    'learning_rate': 0.05,\n",
    "    'iterations': 5000,\n",
    "    'early_stopping_rounds': 300,\n",
    "    'bagging_temperature': 0.5  # less randomness (closer to strong learner)\n",
    "}\n",
    "\n",
    "# Train AutoGluon\n",
    "predictor = TabularPredictor(\n",
    "    label='Item_Outlet_Sales',\n",
    "    problem_type='regression',\n",
    "    eval_metric='root_mean_squared_error'\n",
    "    # eval_metric='mean_absolute_error'\n",
    ").fit(\n",
    "    train_data=train,\n",
    "    # presets='best_quality', \n",
    "    presets='high_quality',\n",
    "    time_limit=600,\n",
    "    save_bag_folds=True, \n",
    "    hyperparameters = {\n",
    "    'RF': {},      # Random Forest\n",
    "    'GBM': {},     # LightGBM\n",
    "    'XGB': {},     # XGBoost\n",
    "    'CAT': {},     # CatBoost\n",
    "    # 'CAT': cat_params,     # CatBoost\n",
    "    'KNN': {},     # KNeighborsDist\n",
    "    'LR': {},      # Linear Regression\n",
    "    'XT': {},      # ExtraTrees (use as Decision Tree alternative)\n",
    "    # 'NN_TORCH': {}\n",
    "    },\n",
    "    verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284a7ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 12 features using 5000 rows with 5 shuffle sets...\n",
      "\t9.23s\t= Expected runtime (1.85s per shuffle set)\n",
      "\t3.0s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "feat_imp = predictor.feature_importance(train)\n",
    "feat_imp.plot(kind='barh', figsize=(6,4))\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f077de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model: KNeighbors_BAG_L1\n",
      "Predicting with model: LightGBM_BAG_L1\n",
      "Predicting with model: RandomForest_BAG_L1\n",
      "Predicting with model: CatBoost_BAG_L1\n",
      "Predicting with model: ExtraTrees_BAG_L1\n",
      "Predicting with model: XGBoost_BAG_L1\n",
      "Predicting with model: LinearModel_BAG_L1\n",
      "Predicting with model: WeightedEnsemble_L2\n",
      "Predicting with model: KNeighbors_BAG_L1_FULL\n",
      "Predicting with model: LightGBM_BAG_L1_FULL\n",
      "Predicting with model: RandomForest_BAG_L1_FULL\n",
      "Predicting with model: CatBoost_BAG_L1_FULL\n",
      "Predicting with model: ExtraTrees_BAG_L1_FULL\n",
      "Predicting with model: XGBoost_BAG_L1_FULL\n",
      "Predicting with model: LinearModel_BAG_L1_FULL\n",
      "Predicting with model: WeightedEnsemble_L2_FULL\n"
     ]
    }
   ],
   "source": [
    "# Check predictions for individual models\n",
    "model_names = predictor._trainer.get_model_names()\n",
    "model_preds = {}\n",
    "\n",
    "for model in model_names:\n",
    "    print(f\"Predicting with model: {model}\")\n",
    "    try:\n",
    "        model_preds[model] = predictor.predict(test, model=model)\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction failed for model {model}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c490cdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNeighbors_BAG_L1': 0       1305.900146\n",
       " 1       1512.830811\n",
       " 2       2319.647217\n",
       " 3       1700.586304\n",
       " 4       4142.075195\n",
       "            ...     \n",
       " 5676     939.044312\n",
       " 5677    2378.104492\n",
       " 5678    1172.473755\n",
       " 5679    4576.842285\n",
       " 5680    1792.466797\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'LightGBM_BAG_L1': 0       1713.295410\n",
       " 1       1394.515015\n",
       " 2        594.186157\n",
       " 3       2482.870605\n",
       " 4       6173.729980\n",
       "            ...     \n",
       " 5676    2244.193115\n",
       " 5677    2567.203369\n",
       " 5678    1798.934448\n",
       " 5679    3611.658447\n",
       " 5680    1296.654419\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'RandomForest_BAG_L1': 0       1608.217651\n",
       " 1       1340.255371\n",
       " 2        708.590942\n",
       " 3       2447.593994\n",
       " 4       6337.204102\n",
       "            ...     \n",
       " 5676    2410.635498\n",
       " 5677    2773.099121\n",
       " 5678    1940.205566\n",
       " 5679    3678.473877\n",
       " 5680    1450.458618\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'CatBoost_BAG_L1': 0       1688.705566\n",
       " 1       1444.375000\n",
       " 2        617.679199\n",
       " 3       2519.801514\n",
       " 4       5972.045898\n",
       "            ...     \n",
       " 5676    2254.915527\n",
       " 5677    2530.338867\n",
       " 5678    1868.640015\n",
       " 5679    3540.353271\n",
       " 5680    1268.115356\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'ExtraTrees_BAG_L1': 0       1629.030640\n",
       " 1       1496.092529\n",
       " 2        800.932983\n",
       " 3       2313.628418\n",
       " 4       5761.755371\n",
       "            ...     \n",
       " 5676    2292.913086\n",
       " 5677    2416.026123\n",
       " 5678    1744.893188\n",
       " 5679    4166.581055\n",
       " 5680    1444.621826\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'XGBoost_BAG_L1': 0       1672.566895\n",
       " 1       1373.308838\n",
       " 2        647.630127\n",
       " 3       2444.835205\n",
       " 4       6086.485352\n",
       "            ...     \n",
       " 5676    2264.410156\n",
       " 5677    2610.548340\n",
       " 5678    1850.675903\n",
       " 5679    3531.734131\n",
       " 5680    1370.938599\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'LinearModel_BAG_L1': 0       1787.784058\n",
       " 1       1505.242920\n",
       " 2       2442.654541\n",
       " 3       2191.010498\n",
       " 4       5249.222656\n",
       "            ...     \n",
       " 5676    2545.513672\n",
       " 5677    3077.182617\n",
       " 5678    2000.559814\n",
       " 5679    2813.571777\n",
       " 5680    1680.088135\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'WeightedEnsemble_L2': 0       1686.845825\n",
       " 1       1436.108276\n",
       " 2        626.208313\n",
       " 3       2501.107422\n",
       " 4       5990.392090\n",
       "            ...     \n",
       " 5676    2256.460693\n",
       " 5677    2535.549072\n",
       " 5678    1855.636230\n",
       " 5679    3573.031738\n",
       " 5680    1287.212402\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'KNeighbors_BAG_L1_FULL': 0       1305.900146\n",
       " 1       1512.830811\n",
       " 2       2319.647217\n",
       " 3       1700.586304\n",
       " 4       4142.075195\n",
       "            ...     \n",
       " 5676     939.044312\n",
       " 5677    2378.104492\n",
       " 5678    1172.473755\n",
       " 5679    4576.842285\n",
       " 5680    1792.466797\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'LightGBM_BAG_L1_FULL': 0       1698.827393\n",
       " 1       1388.431641\n",
       " 2        603.449585\n",
       " 3       2500.237305\n",
       " 4       6164.583496\n",
       "            ...     \n",
       " 5676    2249.094971\n",
       " 5677    2492.603027\n",
       " 5678    1777.585938\n",
       " 5679    3585.584717\n",
       " 5680    1295.648682\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'RandomForest_BAG_L1_FULL': 0       1608.217651\n",
       " 1       1340.255371\n",
       " 2        708.590942\n",
       " 3       2447.593994\n",
       " 4       6337.204102\n",
       "            ...     \n",
       " 5676    2410.635498\n",
       " 5677    2773.099121\n",
       " 5678    1940.205566\n",
       " 5679    3678.473877\n",
       " 5680    1450.458618\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'CatBoost_BAG_L1_FULL': 0       1787.237671\n",
       " 1       1389.740234\n",
       " 2        620.948792\n",
       " 3       2574.168457\n",
       " 4       6133.352539\n",
       "            ...     \n",
       " 5676    2249.361328\n",
       " 5677    2574.641602\n",
       " 5678    1928.962646\n",
       " 5679    3639.860596\n",
       " 5680    1260.644775\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'ExtraTrees_BAG_L1_FULL': 0       1629.030640\n",
       " 1       1496.092529\n",
       " 2        800.932983\n",
       " 3       2313.628418\n",
       " 4       5761.755371\n",
       "            ...     \n",
       " 5676    2292.913086\n",
       " 5677    2416.026123\n",
       " 5678    1744.893188\n",
       " 5679    4166.581055\n",
       " 5680    1444.621826\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'XGBoost_BAG_L1_FULL': 0       1654.891846\n",
       " 1       1379.760132\n",
       " 2        639.697571\n",
       " 3       2458.337158\n",
       " 4       6238.686523\n",
       "            ...     \n",
       " 5676    2239.379395\n",
       " 5677    2492.680420\n",
       " 5678    1845.209839\n",
       " 5679    3591.781982\n",
       " 5680    1304.214355\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'LinearModel_BAG_L1_FULL': 0       1834.458130\n",
       " 1       1527.986816\n",
       " 2       2482.319824\n",
       " 3       2119.604004\n",
       " 4       5577.290527\n",
       "            ...     \n",
       " 5676    2600.072754\n",
       " 5677    3094.517090\n",
       " 5678    1991.710571\n",
       " 5679    2762.649414\n",
       " 5680    1591.780029\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32,\n",
       " 'WeightedEnsemble_L2_FULL': 0       1761.162964\n",
       " 1       1393.382568\n",
       " 2        628.882874\n",
       " 3       2546.339600\n",
       " 4       6129.071777\n",
       "            ...     \n",
       " 5676    2250.363770\n",
       " 5677    2553.484619\n",
       " 5678    1900.513428\n",
       " 5679    3653.861084\n",
       " 5680    1275.476318\n",
       " Name: Item_Outlet_Sales, Length: 5681, dtype: float32}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a968b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "test_pred = predictor.predict(test).clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b9c997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict & Submission\n",
    "test_pred = predictor.predict(test).clip(lower=0)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Item_Identifier': test_original_ids['Item_Identifier'].values,\n",
    "    'Outlet_Identifier': test_original_ids['Outlet_Identifier'].values,\n",
    "    'Item_Outlet_Sales': test_pred.values \n",
    "    # 'Item_Outlet_Sales': np.square(test_pred.values) # Scale back to original range\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23a2dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Ensemble Weights: {'CatBoost_BAG_L1': 0.783, 'LightGBM_BAG_L1': 0.087, 'XGBoost_BAG_L1': 0.087, 'ExtraTrees_BAG_L1': 0.043} \n",
    "# According to the selected Ensemble model, CatBoost is the best model\n",
    "# However upon multiple submissions, observed that CatBoost is underforecasting the sales\n",
    "# Few things to try:\n",
    "# 1. Try different hyperparameters for CatBoost\n",
    "# 2. Try target variable transformations to square root just for CatBoost\n",
    "# 3. Missing drivers of spikes (promos/season/holiday/price changes), adding more categorical features\n",
    "# 4. Evaluation choice: optimizing RMSE can still prefer slight underprediction if extremes are rare, can consider tweedie loss\n",
    "# 5. Hyperparameter tuning for CatBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "common-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
